{
    "comic_number": 2295,
    "explanation": "{{comic\n| number    = 2295\n| date      = April 17, 2020\n| title     = Garbage Math\n| image     = garbage_math.png\n| titletext = 'Garbage In, Garbage Out' should not be taken to imply any sort of conservation law limiting the amount of garbage produced.\n}}\n\n==Explanation==\nThis comic illustrates the \"{{w|garbage in, garbage out}}\" concept using mathematical expressions. It shows how, if you have garbage as inputs to your calculations, then you will likely get garbage as a result, except when you multiply by zero, which eliminates all uncertainty of the result. \n\nThe propagation of errors in {{w|arithmetic}}, other {{w|mathematical operations}}, and {{w|statistics}} is described in colloquial terms. Numbers with low precision are termed garbage, while numbers with high precision are called precise. The table below quantifies the change in precision from the operands to their result in terms of their {{w|variance}}, represented by &sigma;, the Greek lowercase letter sigma, equal to the {{w|standard deviation}}, or the square root of the variance. Variance or standard deviation are common specifications of uncertainty (as an alternative to, for example, a {{w|tolerance interval}}.)\n\nThe {{w|accuracy and precision}} of mathematical operations correspond to the rules of {{w|Propagation_of_uncertainty#Example_formulae|propagation of uncertainty}}, where a \"garbage\" number would correspond to an estimate with a high degree of uncertainty, and a precise number has low uncertainty. The uncertainty of the result of such operations will usually correspond to the term with the highest uncertainty. The rule about N pieces of independent garbage used to calculate an {{w|arithmetic mean}} reflects how the {{w|central limit theorem}} predicts that the uncertainty (or {{w|standard error}}) of an estimate will be reduced when independent estimates are averaged.\n\n{| class=\"wikitable\"\n!Formula as shown\n!Resulting uncertainty\n!Explanation\n|-\n|Precise number + Precise number = Slightly less precise number\n|<math>\\mathop\\sigma(X+Y)=\\sqrt{\\mathop\\sigma(X)^2+\\mathop\\sigma(Y)^2}</math>\n|{{Nowrap|If we know absolute error bars, then adding two precise numbers will}} at worst add the sizes of the two error bars. For example, if our precise numbers are 1 (±10<sup>-6</sup>) and 1 (±10<sup>-6</sup>), then our sum is 2 (±2·10<sup>-6</sup>). It is possible to lose a lot of relative precision, if the resultant sum is close to zero as a result of adding a number to its approximate negation, a phenomenon known as {{w|catastrophic cancellation}}. Therefore, both of the numbers must be positive for the stated assertion to be true.\n|-\n|Precise number × Precise number = Slightly less precise number\n|<math>\\mathop\\sigma(X\\times Y)\\cong</math><br><br><math>\\sqrt{\\mathop\\sigma(X)\\times Y^2+\\mathop\\sigma(Y)\\times X^2}</math>\n|Here, instead of absolute error, relative error will be added. For example, if our precise numbers are 1 (±10<sup>-6</sup>) and 1 (±10<sup>-6</sup>), then our product is 1 (±2·10<sup>-6</sup>).\n|-\n|Precise number + Garbage = Garbage\n|<math>\\mathop\\sigma(X+Y)=\\sqrt{\\mathop\\sigma(X)^2+\\mathop\\sigma(Y)^2}</math>\n|If one of the numbers has a high absolute error, and the numbers being added are of comparable size, then this error will be propagated to the sum. \n|-\n|Precise number × Garbage = Garbage\n|<math>\\mathop\\sigma(X\\times Y)\\cong</math><br><br><math>\\sqrt{\\mathop\\sigma(X)\\times Y^2+\\mathop\\sigma(Y)\\times X^2}</math>\n|Likewise, if one of the numbers has a high relative error, then this error will be propagated to the product. Here, this is independent of the sizes of the numbers.\n|-\n|√<span style=\"border-top:1px solid; padding:0 0.1em;\">Garbage</span> = Less bad garbage\n|<math>\\mathop\\sigma(\\sqrt X)\\cong\\frac{\\mathop\\sigma(X)}{2\\times\\sqrt X} </math>\n| When the square root of a number is computed, its relative error will be halved. Depending on the application, this might not be all that much ''better'', but it's at least ''less bad''.\n|-\n|Garbage<sup>2</sup> = Worse garbage\n|<math>\\mathop\\sigma(X^2)\\cong2\\times X\\times\\mathop\\sigma(X)</math>\n|Likewise, when a number is squared, its relative error will be doubled. This is a corollary to multiplication adding relative errors.\n|-\n|<math>\\frac{1}{N}\\sum(</math>N pieces of statistically independent garbage<math>)</math> = Better garbage\n|<math>{\\sigma}_\\bar{X}\\ = \\frac{\\sigma_X}{\\sqrt{N}}</math>\n|By aggregating many pieces of statistically independent observations (for instance, surveying many individuals), it is possible to reduce relative error to the {{w|Standard_error#Standard_error_of_the_mean|standard error of the mean}}. This is the basis of statistical sampling and the {{w|central limit theorem}}.\n|-\n|Precise number<sup>Garbage</sup> = Much worse garbage\n|<math>\\mathop\\sigma(b^X)\\cong|b^X|\\times\\mathop{\\mathrm{ln}}b\\times\\sigma(X)</math>\n|The exponent is very sensitive to changes, which may also magnify the effect based on the magnitude of the precise number.\n|-\n|Garbage – Garbage = Much worse garbage\n|<math>\\mathop\\sigma(X-Y)=\\sqrt{\\mathop\\sigma(X)^2+\\mathop\\sigma(Y)^2}</math>\n|This line involves catastrophic cancellation. If both pieces of garbage are about the same (e.g. if their error bars overlap), then it is possible that the answer is positive, zero, or negative.\n|-\n|<math>\\frac{\\text{Precise number}}{\\text{Garbage}-\\text{Garbage}}</math> = Much worse garbage, possible division by zero\n|<math>\\mathop\\sigma\\left(\\frac{a}{X-Y}\\right)\\cong</math><br><br><math>\\frac {|a|}{(X-Y)^2}\\times\\sqrt{\\mathop\\sigma(X)^2+\\mathop\\sigma(Y)^2}</math>\n|Indeed, as with above, if error bars overlap then we might end up dividing by zero. Division by zero is strictly undefined.[https://www.youtube.com/watch?v=dHdg1yn1SgE]\n|-\n|Garbage × 0 = Precise number\n|<math>\\mathop\\sigma(0)=0</math>\n|Multiplying anything by 0 results in 0, an extremely precise number in the sense that it has no error whatsoever since we supply the 0 ourselves. This is equivalent to discarding garbage data from a statistical analysis.\n|}\n\nThe title text refers to the computer science maxim of \"garbage in, garbage out,\" which states that when it comes to computer code, supplying incorrect initial data will produce incorrect results, even if the code itself accurately does what it is supposed to do. As we can see above, however, when plugging data into mathematical formulas, this can possibly magnify the error of our input data, though there are ways to reduce this error (such as aggregating data). Therefore, the quantity of garbage is not necessarily {{w|Conservation law|conserved}}, in contrast to other scientific quantities like energy and momentum that are always conserved. Alternatively, this could be take as a pun on environmental conservation efforts, which can often involve recycling one's trash. However, the computer science maxim of \"garbage in, garbage out,\" has nothing to do with actual garbage.\n\n==Transcript==\n\n[A series of mathematical equations are written from top to bottom]\n\nPrecise number + Precise number = Slightly less precise number\n\nPrecise number × Precise number = Slightly less precise number\n\nPrecise number + Garbage = Garbage\n\nPrecise number × Garbage = Garbage\n\n√<span style=\"border-top:1px solid; padding:0 0.1em;\">Garbage</span> = Less bad garbage\n\nGarbage² = Worse garbage\n\n1/N Σ (N pieces of statistically independent garbage) = Better garbage\n\n(Precise number)<sup>Garbage</sup> = Much worse garbage\n\nGarbage – Garbage = Much worse garbage\n\nPrecise number / ( Garbage – Garbage ) = Much worse garbage, possible division by zero\n\nGarbage × 0 = Precise number\n\n{{comic discussion}}\n[[Category:Math]]"
}